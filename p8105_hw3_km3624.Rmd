---
title: "Homework 3"
author: "Phoebe Mo"
date: "2020-10-08"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Problem 1
```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. Observations are the level of items in orders by user. There are
user/order variables -- user ID, order ID, order date and order hour. There
are also item variable -- name, aisle, department, and some numeric codes.

How many aisles, and which are most items from?
```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

Let's make a plot
```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Let's make a table
```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```

Apple vs ice cream..

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

### Problem 2

Load, tidy, and otherwise wrangle the data

```{r}
accel_df =
  read.csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_prefix = "activity_",
    names_to = "min_of_day",
    values_to = "activity_count"
  ) %>%
  mutate(
    dow = ifelse(day == "Saturday", "weekend",
          ifelse(day == "Sunday", "weekend", "weekday")),
    min_of_day = as.numeric(min_of_day)
  )
```
This resulting dataset has totally `r nrow(accel_df)` observations, each is about the
activity count in each minute of a day in a specific week. There are variables: week,
day_id, day, dow(day of week), minute of the day, and the activity counts. There are totally five weeks and 35 days in this dataset, and the mean activity count in these 35 days is `r mean(pull(accel_df, activity_count))`

Now create a table showing total activity over the day

```{r}
accel_df %>%
  group_by(week, day) %>%
  summarize(
    activity_daily = sum(activity_count)
  ) %>%
  pivot_wider(
    names_from = "day",
    values_from = "activity_daily"
  ) %>%
  select("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday") %>%
  knitr::kable()
```

Observing the table, it is significant that in week 1, there are less activity counts, especially in weekdays and Saturday. Also, the activity counts during Tuesday and Wednesday are relatively stable. The activity counts on Sunday is mostly decreasing during these 5 weeks.

Now, make a plot showing 24-hour activity time courses for each day

```{r}
accel_df %>%
  group_by(day) %>%
  ggplot(aes(x = min_of_day, y = activity_count, color = day)) +
  geom_line(alpha = 0.5) +
  theme(legend.position = "bottom", plot.title = element_text(size = 15, hjust = 0.5)) +
  labs(
    title = "Activity during a day",
    x = "minute (min)",
    y = "activity counts"
  )
```

Observing the plot, we can find that during a day, the activity count starts to increase from approximately 270 min of the beginning of every day. On Friday, the patient has significant higher activity at around 8pm and on Sunday, there is much more activity at around noon. For other days, their activity count is relatively stable during a day after the early morning.


